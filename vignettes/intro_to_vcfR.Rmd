---
title: "Introduction to vcfR"
author: "Brian J. Knaus"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to vcfR}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---


vcfR is a package intended to help view, understand and filter data in vcf format files.


## Preliminaries

Input files frequently present challenges to analysis.
A common problem I see is that chromosome names are not standardized among vcf, fasta and gff format files.
This presents work for the analyst.
I suggest reading these files into R, syncronizing the names in R and then proceeding with downstream analyses.
The other option I see is to create a set of files where the data is identical to the initial files, but the names have been syncronized.
This later choice results in the creation of files which are largely redundant which I feel is unnecessary.


Reading in of the [vcf](http://www.1000genomes.org/node/101) file can be performed with a function in vcfR.


```{r, eval=FALSE}
library(vcfR)
vcf_file <- system.file("extdata", "pinf_sc1_100_sub.vcf.gz", package = "vcfR")
vcf <- read.vcf(vcf_file, verbose = FALSE)
```


The function **read.vcf()** takes the filename you specify and uses it to read the file into a **vcfR** object.  The **vcfR** object is an S4 class object with three slots containing the metadata, the fixed data and the genotype data.  This object provides a known organization of the data so that downstream functions can easily access it.


Genomic reference sequence files are typically in fasta format files.
These can be read in using the package ape.


```{r, eval=FALSE}
library(ape)
seq_file <- system.file("extdata", "pinf_sc100.fasta", package = "vcfR")
dna <- ape::read.dna(seq_file, format = "fasta")
```


Annotation files (e.g., [gff](http://sequenceontology.org/resources/gff3.html)), files which contain coordinates of features such as start and end points of genes, are tabular and can be read in with typical R functions.


```{r, eval=FALSE}
gff_file <- system.file("extdata", "pinf_sc100.gff", package = "vcfR")
gff <- read.table(gff_file, sep="\t")
```


Once the data has been read into memory and modifications can be made to chromosome names or any other inconsistencies and one can proceed.


vcfR was designed to work on individual chromosomes, or supercontigs or contigs, depending on the state of your genome.
Reading an entire genome into memory may present a technical challenge when there is a lot of data, the genome is large or there are a lot of saples.
Working on chromosomes appears to be a natural way to decompose this problem.
Once you have read an object into R you may therefore want to subset it to data for a single chromosome, if necessary.



## Workflow


Work begins with a variant call format file (vcf).
A reference files (fasta) and an annotation file are also suggested.
These later two files are not necessary, but I feel they contribute substantially.
The below flowchart outlines the major steps involved with vcfR use.



![](vcfR_flowchart.png)



The green rectangles contain functions that the user will want to become familiar with.
There are effectively three phases in the workflow: reading in data, processing the objects in memory and plotting the data graphically.
Reading in the data frequently presents a bottleneck.
Unfortunately, this is typically due to the time it takes to read from a drive and therefore may not be anything I can improve on.
Once the data are in memory we can manipulate it.
I've been rewriting a number of function in C++ to try to improve the performance of these function.
Lastly, we visualize the objects. Visualisation relies on R's base graphics package.
This is also something that I am not likely to be able to improve on if it becomes a bottleneck.
By dividing the analysis into these three phases I've divided that workflow into things I may be able to improve upon through my code writing, and things which I have little control over.



## Creating objects from data


Once the data are in memory we can use it to create a **Chrom** object with the function **create_chrom()**.
The create_chrom() function creates a new Chrom object and populates it with data you provided it.  


```{r}
library(vcfR)
chrom <- create_chrom(name='Supercontig_1.100', vcf=vcf, seq=dna, ann=gff)
```


Note that here the names of our three data sources are identical.
This is not always the case.
If these names are not identical a warning will result to make sure the user understands their data.



The parameter 'name' is a name you can assign to your object.
This information is used when plotting the Chrom object.
The vcf object should be of class vcfR, which was most likely created with the function read.vcf().
This object is inserted into the chrom object with the function **vcf2chrom()**.

The 'seq' should be a DNAbin object with one sequence in it.
This sequence will be inserted into the Chrom object with the function **seq2chrom()**.
If a sequence is not provided, seq2chrom will infer the length of your chromosome from the maximum position in the vcf file.


The 'ann' should be a [gff](http://sequenceontology.org/resources/gff3.html) type of table.  These can typically read in with base R functions such as read.table.  This table will then be inserted into the Chrom object by **ann2chrom()**.  This function will check to see if columns 4 and 5 ("start" and "end") are numeric.  If not, it will try to recast them as so.



## Processing objects


Once the Chrom object has been created a few processing steps are made.
First, you may want to get a quick look at some of your data.
This can be done with the plot function.



```{r, fig.height=6, fig.width=6, dev='Cairo_png'}
plot(chrom)
```



No SNP densities are not found at this point because this data results from windowing analyses performed by **proc_chrom()** (see below).
We can see that mapping qualities (MQ) are all fairly high.
Because of this, if we would like to filter on this parameter we now know that we would have to employ a high threshold.
The qualities (QUAL) appear bimodal.
It has been my exprience that this is typical for this parameter.
The values appear to either be 999 or something below 200.
This bimodality suggests this to be a reasonable parameter to apply a threshold for, somewhere between 200 and 999.

Note that vcf files created by different softwares may or may not have these fields.



We can use the **masker()** function to try to filter out data which we do not have high confidence in.
The masker() function uses quality, depth and mappiing quality to try to select only high quality variants.
By default, only variants with a quality of 999 or better, a depth between the 0.25 and 0.75 percentiles and a mapping quality between 20 and 50 are used.
Variants deemed to be of low quality are not deleted from the dataset.
Instead, a logical vector is created to indicate which variants have or have not been filtered.
This maintains the geometry of the data matrices throughout the analyisis and allows the user to easily undo any changes.



```{r, fig.height=6, fig.width=6, dev='Cairo_png'}
chrom <- masker(chrom)
plot(chrom)
```


Now all of the qualities are at 999.
(Note that the R histogram function has a little trouble when its given data of all one value.
Its really intended for a distribution of data.)


Once we're satisfied with which variants we want to consider to be of high quality we can process the Chrom object with **proc_chrom()**.
This function calls several helper functions to process the variant, sequence and annotation data for visualization.


The function **regex.win()** defines rectangles for where called sequence (A, C, G and T) occur as well as where ambiguous nucleotides occur (N) which are used later for plotting.
This function also defines rectangles for annotated features, also for plotting.


The function **var.win()** performs windowing analyses on the data.
Currently it summarizes variant count per window as well as G/C content per window.


The function **gt2popsum()** calculates some population genetic summaries.
This function is rather experimental and some of the summaries may not be quite correct.



```{r, fig.height=6, fig.width=6, dev='Cairo_png'}
chrom <- proc_chrom(chrom, verbose=TRUE)
plot(chrom)
```


Now that we've processed our Chrom object, we have variant counts per window.
We're also ready to move on to more complex plots.



## Visualizing data


At this point we've input three types of data (variant, sequence and annotation), inserted them into a Chrom object, masked variants we feel were not of high quality and processed some summaries of these data.
We can now move on to visualizing these data.


The function **chromoqc()** uses the R function layout to make composite plots of the data.  These plots can include barplots as well as scatterplots which have chromosomal coordinates.



```{r, fig.height=6, fig.width=6, dev='Cairo_png'}
chromoqc(chrom)
```


This example uses the *Phytophthora infestans* mitochondrial genome.
This mitochondrion has a notable A/T bias, which is in agreement with published accounts.


Variants of this function, which are actually all wrappers for the funciton **chromo()**, create similar plots.



```{r, fig.height=6, fig.width=6, dev='Cairo_png'}
chromohwe(chrom, dot.alpha='ff')
```


Mitochondria are haploid, so they are expected to violate assumptions of Hardy-Weinberg equilibrium.  
Variants inferred to be in equilibrium would have been plotted in green.
Here, all variants are plotted in red to indicate that they significantly deviate from Hardy-Weinberg equilibrium.


The user can also include their own data to plot.
Here we simulate data as an example.



```{r, fig.height=6, fig.width=6, dev='Cairo_png'}
set.seed(10)
x1 <- as.integer(runif(n=20, min=1, max=chrom@len))
y1 <- runif(n=length(x1), min=1, max=100)
chromodot(chrom, x1=x1, y1=y1, label1="Simulated data", dot.alpha="ff")
```



Thus far we've been looking at per variant summaries over all samples.
This information is typically found in the fixed portion of a vcf file (the first 8 columns of the file).
Beyond these eight colomns are a flexible number of columns for each sample.
Different softwares will place different types of data here.
We can use the function **extract.gt()** to extract specified fields from the genotype region of the vcf data.
Here we extract genotype quality (GQ) for each sample and each variant.



```{r}
gq <- extract.gt(chrom, element="GQ", as.numeric=TRUE)
gq[1:4,1:10]
```



We can then visualize this data with a heatmap.



```{r, fig.height=6, fig.width=6, dev='Cairo_png'}
heatmap.bp(gq)
```


Each sample is in a column and each variant is in a row.
The sequence begins at thte bottom of the plot and extends to the top of the plot.
Barplots summarize column and row sums.
We can see a few samples near the center of the plot have relatively low genotype qualities.
These samples may be considered candidates for mitigation.
For example, they may be excluded from subsequent analyses.
Or they may be resequenced.
Or they may be omitted from variant discovery steps but included in variant calling steps.
It is up to the investigator to determine what is low quality and how to mitigate it.
There is also a region at the bottom of the plot where most samples appear to have low genotype quality.
A researcher may consider omitting this region from further analysis if they deem this quality to be unacceptable.
In order to remove samples, the data may be subset using the square brackets `[]`.
In order to omit variants, their mask elements should be set to FALSE.



When there are large numbers of variants, it may be more convenient to summarize regions using a windowing analysis.  This can be done with the function **windowize_NM**.


```{r}
gqw <- windowize_NM(gq, pos=chrom@var.info$POS, starts=chrom@win.info$start, ends=chrom@win.info$end)
gqw[1:6,1:8]
```


We can take z-scores to help us determine what values may be exceptional.


```{r}
gqwz <- z_score(gqw)
hist(gqwz[,1])
```


And create another heatmap.



```{r, fig.height=6, fig.width=6, dev='Cairo_png'}
heatmap.bp(gqwz)
```


Because the marginal barplots summarize z-scores, some of them are now negative.
The first 1 kbp has no variants.
This results in a low score.
When zero is meaningful, this may be appropriate.
When zero means a lack of data, it may be appropriate to set data with consisting of zeros data as NA.


An important difference between the per variant perspective and the windowed perspective is that the variant perspective is removed from the chromosomal coordinates.
It only has values where variants have been observed.
Region with high variant counts become over-represented while regions lacking variants are omitted.
Windowing returns the chomosomal coordinates.



The region of low quality for windows 5, 6 and 7 correspond to the region between 4001 - 7000 bp.
When we compare this to the chromoqc plot above, we see that this region has a low read depth as well as a region where no variants were called.
This may represent a region with assembly or mapping issues.
One option may be to further explore this region to attempt to address this issue.
An alternative may be to censor this region and focus on the remainder of the chromosome.



When sequence depth information is included, these methods can be used to explore copy number variation.



## Output of data

One of the goals of the package vcfR is to help investigators understand and explore their data.
Once they've gained an understanding of this data, they will likely want to act upon it.
One way to act upon this understanding is to use their aquired comprehension of their data to filter it to what they feel is of adequate quality.


### Output to vcf file

Within the framework of the package vcfR, the filtering and output of variants determined to be of adequate quality can be accomplished with the function **write.vcf**.
This function takes a vcfR object and optionally subsets it using the mask, created in previous steps, and outputs it to a vcf format file.
This file should be usable by all vcf format compliant softwares for downstream analyses.


### Conversion to other R objects

Ideally, objects created in vcfR should be easily transferrable to other R object which contain similar data.
For example, an object of class 'vcfR' should have a translator function to convert it to objects supported by other packages.
For example, a translator function which would help convert a vcfR::vcfR object to an object supported by pegas would allow seamless translation among these identical data types.
These functions do not currently exist.
But thrugh the establishmet of standards these translations should be easily facilitated.



## Future directions

The pacage vcfR aims to input vcf type data and output filtered vcf type data.
Windowing functions within the package aim to identify regions which may contain sub-optimal data.
Future work in this package may try to construct genomic regioins files (e.g., \*.gff or \*.bed files) which annotate these regions.
This output could be utilized by other software to focus variant discovery and variant calling on regions of high confidence.



